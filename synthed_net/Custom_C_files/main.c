/*******************************************************************************
* Copyright (C) 2019-2023 Maxim Integrated Products, Inc., All rights Reserved.
*
* This software is protected by copyright laws of the United States and
* of foreign countries. This material may also be protected by patent laws
* and technology transfer regulations of the United States and of foreign
* countries. This software is furnished under a license agreement and/or a
* nondisclosure agreement and may only be used or reproduced in accordance
* with the terms of those agreements. Dissemination of this information to
* any party or parties not specified in the license agreement and/or
* nondisclosure agreement is expressly prohibited.
*
* The above copyright notice and this permission notice shall be included
* in all copies or substantial portions of the Software.
*
* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
* OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
* MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
* IN NO EVENT SHALL MAXIM INTEGRATED BE LIABLE FOR ANY CLAIM, DAMAGES
* OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
* ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
* OTHER DEALINGS IN THE SOFTWARE.
*
* Except as contained in this notice, the name of Maxim Integrated
* Products, Inc. shall not be used except as stated in the Maxim Integrated
* Products, Inc. Branding Policy.
*
* The mere transfer of this software does not imply any licenses
* of trade secrets, proprietary technology, copyrights, patents,
* trademarks, maskwork rights, or any other form of intellectual
* property whatsoever. Maxim Integrated Products, Inc. retains all
* ownership rights.
*******************************************************************************/

// widerfacenet
// This file was @generated by ai8xize.py --test-dir synthed_net --prefix widerfacenet --checkpoint-file trained/widerfaceonetv1_trained-q.pth.tar --config-file networks/widerfacenet.yaml --sample-input tests/sample_widerfaces.npy --device MAX78000 --compact-data --mexpress --timer 0 --display-checkpoint --verbose --overwrite --board-name FTHR_RevA
// ...and edited afterwards by Lionnus Kesting :)

#include <stdlib.h>
#include <stdint.h>
#include <string.h>
#include <stdio.h>
#include "mxc.h"
#include "cnn.h"
#include "sampledata.h"
#include "sampleoutput.h"
// Include camera demo
#include "post_process.h"
#include "dma.h"
#include "led.h"
#include "camera.h"
#include "config.h"

volatile uint32_t cnn_time; // Stopwatch

void fail(void)
{
  printf("\n*** FAIL ***\n\n");
  while (1);
}

// 3-channel 48x48 data input (6912 bytes total / 2304 bytes per channel):
// HWC 48x48, channels 0 to 2
static const uint32_t input_0[] = SAMPLE_INPUT_0;
const uint32_t *input = input_0;

void load_input(void)
{
#ifdef USE_SAMPLEDATA
  // This function loads the sample data input -- replace with actual data
  memcpy32((uint32_t *)0x50400000, input, IMAGE_SIZE_X * IMAGE_SIZE_Y);
#else // Camera
  uint8_t *frame_buffer;
  uint8_t *buffer;
  uint32_t imgLen;
  uint32_t w, h, x, y;
  uint8_t r, g, b;
  uint32_t *cnn_mem = (uint32_t *)0x50400000;
  //uint32_t color;

  camera_start_capture_image();

  while (!camera_is_image_rcv()) {}

  camera_get_image(&frame_buffer, &imgLen, &w, &h);
  buffer = frame_buffer;

  printf("Width:%d Height:%d\n", w, h);

  for (y = 0; y < h; y++) {
      for (x = 0; x < w; x++) {
          r = *buffer++;
          g = *buffer++;
          b = *buffer++;
          buffer++; // skip msb=0x00
          // change the range from [0,255] to [-128,127] and store in buffer for CNN
          *cnn_mem++ = ((b << 16) | (g << 8) | r) ^ 0x00808080;
}
}
#endif
}
// Expected output of layer 5 for widerfacenet given the sample input (known-answer test)
// Delete this function for production code
static const uint32_t sample_output[] = SAMPLE_OUTPUT;

int check_output(void)
{
  int i;
  uint32_t mask, len;
  volatile uint32_t *addr;
  const uint32_t *ptr = sample_output;

  while ((addr = (volatile uint32_t *) *ptr++) != 0) {
    mask = *ptr++;
    len = *ptr++;
    for (i = 0; i < len; i++)
      if ((*addr++ & mask) != *ptr++) {
        printf("Data mismatch (%d/%d) at address 0x%08x: Expected 0x%08x, read 0x%08x.\n",
               i + 1, len, addr - 1, *(ptr - 1), *(addr - 1) & mask);
        return CNN_FAIL;
      }
  }

  return CNN_OK;
}

static int32_t ml_data[CNN_NUM_OUTPUTS];
static q15_t ml_softmax[CNN_NUM_OUTPUTS]; //Only one node for face classification


int main(void)
{
  // Wait for PMIC 1.8V to become available, about 180ms after power up.
  MXC_Delay(200000);
  /* Enable camera power */
  //Camera_Power(POWER_ON);
  printf("\n\nFace Detection MAXIM7800 - Lionnus Kesting\n");
  MXC_ICC_Enable(MXC_ICC0); // Enable cache

  // Switch to 100 MHz clock
  MXC_SYS_Clock_Select(MXC_SYS_CLOCK_IPO);
  SystemCoreClockUpdate();

  printf("Waiting...\n");

  // DO NOT DELETE THIS LINE:
  MXC_Delay(SEC(2)); // Let debugger interrupt if needed

  // Time for some extra performance?
  // Configure P2.5, turn on the CNN Boost
    // mxc_gpio_cfg_t gpio_out;
    // gpio_out.port = MXC_GPIO2;
    // gpio_out.mask = MXC_GPIO_PIN_5;
    // gpio_out.pad = MXC_GPIO_PAD_NONE;
    // gpio_out.func = MXC_GPIO_FUNC_OUT;
    // MXC_GPIO_Config(&gpio_out);
    // MXC_GPIO_OutSet(gpio_out.port, gpio_out.mask);

    // Setup variables for camera
    int xx = IMAGE_SIZE_X;
    int yy = IMAGE_SIZE_Y;
    printf("Camera setup for: x %d  y %d\n", xx, yy);

#if !defined(USE_SAMPLEDATA)
    int dma_channel;
    // Initialize camera.
    printf("Init Camera...");

    // Initialize DMA for camera interface
    MXC_DMA_Init();
    dma_channel = MXC_DMA_AcquireChannel();

    camera_init(CAMERA_FREQ);

    int ret = camera_setup(IMAGE_SIZE_X, IMAGE_SIZE_Y, PIXFORMAT_RGB888, FIFO_THREE_BYTE, USE_DMA,
                           dma_channel);

    if (ret != STATUS_OK) {
        printf("\tError returned from setting up camera. Error %d\n", ret);
        return -1;
    }

#else
    printf("Using Sample Data!\n");
#endif

  // Enable peripheral, enable CNN interrupt, turn on CNN clock
  // CNN clock: APB (50 MHz) div 1
  cnn_enable(MXC_S_GCR_PCLKDIV_CNNCLKSEL_PCLK, MXC_S_GCR_PCLKDIV_CNNCLKDIV_DIV1);
  printf("\n*** CNN Inference Test widerfacenet ***\n");
    
  cnn_init(); // Bring state machine into consistent state
  cnn_load_weights(); // Load kernels 

//while(1) {
  cnn_load_bias(); // Not used in this network
  cnn_configure(); // Configure state machine
  // TO DO: LOad camera input
  load_input(); // Load data input
  LED_On(LED1); // Indicate start of CNN processing
  cnn_start(); // Start CNN processing

  while (cnn_time == 0){
    MXC_LP_EnterSleepMode(); // Wait for CNN
    //__WFI(); // Wait for CNN -> other method?
  //}
  printf("CNN time: %d us\n\n", cnn_time);
  LED_Off(LED1);
  
  cnn_unload((uint32_t *) ml_data);
  softmax_q17p14_q15((const q31_t *) ml_data, 1, ml_softmax); // Pass face classification flag in softmax

  if (check_output() != CNN_OK) printf("--\nTest inference NOT passed\n--\n");
  #ifdef CNN_INFERENCE_TIMER
    printf("Approximate inference time: %u us\n\n", cnn_time);
  #endif

    cnn_disable(); // Shut down CNN clock, disable peripheral

  // Convert first CNN outputs to coordinate values
  float bbox[4] = {0};
  convert_to_bbox((uint32_t *)ml_data, bbox);

  // Convert last CNN output to confidence value
  float confidence_value = ((float)(1000 * ml_softmax[4] + 0x4000) / 32768.0f);
  float confidence_value2 = (q17_14_to_float(ml_data[4])+1)*50;

  printf("\nBBOX x: %.2f, y: %.2f, w: %.2f, h: %.2f\n Confidence: %.2f or %.2f\n", bbox[0], bbox[1], bbox[2], bbox[3], confidence_value, confidence_value2);


}

  return 0;
}

/*
  SUMMARY OF OPS
  Hardware: 13,127,136 ops (12,806,464 macc; 320,672 comp; 0 add; 0 mul; 0 bitwise)
    Layer 0: 2,064,384 ops (1,990,656 macc; 73,728 comp; 0 add; 0 mul; 0 bitwise)
    Layer 1: 8,309,088 ops (8,128,512 macc; 180,576 comp; 0 add; 0 mul; 0 bitwise)
    Layer 2: 2,420,992 ops (2,359,296 macc; 61,696 comp; 0 add; 0 mul; 0 bitwise)
    Layer 3: 299,520 ops (294,912 macc; 4,608 comp; 0 add; 0 mul; 0 bitwise)
    Layer 4: 32,832 ops (32,768 macc; 64 comp; 0 add; 0 mul; 0 bitwise)
    Layer 5: 320 ops (320 macc; 0 comp; 0 add; 0 mul; 0 bitwise)

  RESOURCE USAGE
  Weight memory: 162,976 bytes out of 442,368 bytes total (36.8%)
  Bias memory:   0 bytes out of 2,048 bytes total (0.0%)
*/

