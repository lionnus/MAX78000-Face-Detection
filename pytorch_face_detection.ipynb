{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mDxvjs35_SWd"
   },
   "source": [
    "# Pytorch face detection for ML\n",
    "\n",
    "*Lionnus Kesting (ETHZ)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Zg7cIzwXiBq6"
   },
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "HLlnWjXhg17X",
    "outputId": "739a44f0-b1e3-4282-8eae-d0a681201be4"
   },
   "outputs": [],
   "source": [
    "# Start with the basics\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "# Import ai8x specifics\n",
    "#import ai8x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WY59unFq40v7",
    "outputId": "8f90ed3a-bed6-4e70-d69e-d7e7f4e50f45"
   },
   "outputs": [],
   "source": [
    "#@title Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: %s' % device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset and dataloader classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Custom image dataset class\n",
    "\"\"\"\n",
    "class WIDERFacesDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.annotation_file = os.path.join(self.data_path, \"wider_face_bbx_gt.txt\")\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load data and annotations\n",
    "        self.data, self.annotations = self.load_data()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.data_path, self.annotations[idx]['image'])\n",
    "        image = self.load_image(image_path)\n",
    "        \n",
    "        bboxes = self.annotations[idx]['bboxes']\n",
    "\n",
    "        # Resize image to 128 x 128 and update boundary boxes accordingly\n",
    "        bboxes_resized = self.resize_bbox(bboxes, image.shape[1], image.shape[0], 64,64)\n",
    "        image = cv2.resize(image, (64,64))\n",
    "\n",
    "        #labels = self.annotations[idx]['labels']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "            \n",
    "        return image, torch.tensor([float(i) for i in bboxes_resized[0]])\n",
    "    \n",
    "    def load_data(self):\n",
    "        annotations = []\n",
    "        data = []\n",
    "        \n",
    "        image_files = os.listdir(self.data_path) # list of all the objects in directory, also includes the folder->check for extension to get images\n",
    "\n",
    "        with open(self.annotation_file, 'r') as f:\n",
    "            lines = f.read().splitlines()\n",
    "\n",
    "        i = 0\n",
    "        while(i<len(lines)):\n",
    "                image_name = lines[i]\n",
    "                image_file_path = os.path.join(self.data_path, image_name)\n",
    "                i += 1\n",
    "                num_bboxes = int(lines[i])\n",
    "\n",
    "                bboxes = []\n",
    "                labels = []\n",
    "\n",
    "                # Iterate over the lines containing the boundary box coordinates\n",
    "                for j in range(num_bboxes):\n",
    "                    i += 1\n",
    "                    bbox_data = lines[i].split(' ')\n",
    "                    bbox = [\n",
    "                        int(bbox_data[0]),\n",
    "                        int(bbox_data[1]),\n",
    "                        int(bbox_data[2]),\n",
    "                        int(bbox_data[3])\n",
    "                    ]\n",
    "                    bboxes.append(bbox)\n",
    "                # Fix the stupid fact that it has 0 coordinates if it doesnt have a boundary box\n",
    "                if(num_bboxes==0):\n",
    "                    bbox_data = [0,0,0,0,0,0,0,0,0,0]\n",
    "                    bbox=[0,0,0,0]\n",
    "                    bboxes.append(bbox)\n",
    "                    i+=1\n",
    "                label = {\n",
    "                    'name': image_name.split('/')[1],\n",
    "                    'faces': num_bboxes,\n",
    "                    'type': int(image_name.split(\"--\")[0]),\n",
    "                    'blur': int(bbox_data[4]),\n",
    "                    'expression': int(bbox_data[5]),\n",
    "                    'illumination': int(bbox_data[6]),\n",
    "                    'invalid': int(bbox_data[7]),\n",
    "                    'occlusion': int(bbox_data[8]),\n",
    "                    'pose': int(bbox_data[9])\n",
    "                }\n",
    "                annotation = {\n",
    "                    'image': image_name,\n",
    "                    'bboxes': bboxes,\n",
    "                    'labels': label\n",
    "                }\n",
    "                if(num_bboxes==1 or num_bboxes ==0):\n",
    "                    annotations.append(annotation)\n",
    "                    data.append(image_file_path)\n",
    "                i += 1\n",
    "\n",
    "        return data, annotations\n",
    "    \n",
    "    def resize_bbox(self,bboxes, dim_x_init,dim_y_init, dim_x,dim_y):\n",
    "        bboxes_resized = []\n",
    "        #print(bboxes, dim_x_init,dim_y_init, dim_x,dim_y)\n",
    "        for bbox in bboxes:\n",
    "            # Calculate the scaling factors for width and height\n",
    "            scale_x = dim_x / dim_x_init\n",
    "            scale_y = dim_y / dim_y_init\n",
    "            #print(scale_x,scale_y)\n",
    "            # Convert the coordinates to the new dimensions\n",
    "            bbox_resized = [ int(bbox[0] * scale_x), int(bbox[1] * scale_y), int(bbox[2] * scale_x), int(bbox[3] * scale_y)]\n",
    "            bboxes_resized.append(bbox_resized)\n",
    "        #print(bboxes_resized)\n",
    "\n",
    "        return bboxes_resized\n",
    "    \n",
    "    def load_image(self, path):\n",
    "        # Load and preprocess the image\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "def widerfaces_get_datasets(data, load_train=True, load_test=True):\n",
    "    \"\"\"\n",
    "    Load the WIDER Faces dataset\n",
    "\n",
    "    The images are of multiple sizes, so they are rescaled to a predefined size.\n",
    "    \"\"\"\n",
    "    (data_dir, args) = data\n",
    "\n",
    "    if load_train:\n",
    "        print(\"Loading training dataset\")\n",
    "        train_transform = transforms.Compose([\n",
    "            #Rescale(256),\n",
    "            #RandomCrop(224),\n",
    "            transforms.ToTensor()\n",
    "            #ai8x.normalize()\n",
    "        ])\n",
    "\n",
    "        train_dataset = WIDERFacesDataset(data_path=os.path.join(data_dir, \"widerface\", \"WIDER_train/images\"), transform=train_transform)\n",
    "    else:\n",
    "        train_dataset = None\n",
    "\n",
    "    if load_test:\n",
    "        test_transform = transforms.Compose([\n",
    "            #Rescale(256),\n",
    "            #RandomCrop(224),\n",
    "            transforms.ToTensor()\n",
    "            \n",
    "            #ai8x.normalize()\n",
    "        ])\n",
    "        # Load validation dataset instead of test dataset, since test dataset is unlabeled\n",
    "        test_dataset = WIDERFacesDataset(data_path=os.path.join(data_dir, \"widerface\", \"WIDER_val/images\"), transform=test_transform)\n",
    "    else:\n",
    "        test_dataset = None\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "datasets = [\n",
    "    {\n",
    "        'name': 'widerfaces',\n",
    "        'input': (3, 128, 128),\n",
    "        'output': [('x', float), ('y', float), ('w', float), ('h', float)],\n",
    "        'regression': True,\n",
    "        'loader': widerfaces_get_datasets,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the dataset\n",
    "data_path = 'WIDER_faces/train'\n",
    "#annotation_file = 'wider_face_split/wider_face_train_bbx_gt.txt'\n",
    "print('before dataset')\n",
    "#dataset = WIDERFacesDataset(data_path,{1,2,3,4,5,9})\n",
    "dataset = WIDERFacesDataset(data_path)\n",
    "\n",
    "# Test a specific sample\n",
    "sample = dataset[6]\n",
    "image, bboxes= sample\n",
    "\n",
    "# Inspect the sample\n",
    "print(\"Image shape:\", image.shape)\n",
    "print(\"Bounding boxes:\", bboxes)\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Display the image\n",
    "ax.imshow(image)\n",
    "\n",
    "# Add bounding boxes to the plot\n",
    "for bbox in [bboxes]:\n",
    "    x, y, w, h = bbox\n",
    "    rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_title('Random image with Bounding Boxes')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataloader above"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define plotting function for boundary boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBoundaryBox(image,bbox):\n",
    "    # Create a figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Display the image which is a tensor\n",
    "    ax.imshow(image.permute(1, 2, 0))\n",
    "\n",
    "    x, y, w, h = bbox\n",
    "    rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    # Set axis labels and title\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    #ax.set_title('Image with Boundary box')\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args=0\n",
    "data = ('/home/lionnus/OneDrive/Ubuntu/MLonMCU/maxim7800-face-detection',0)\n",
    "train_dataset,test_dataset= widerfaces_get_datasets(data,load_train=True)\n",
    "\n",
    "sample = train_dataset[99]\n",
    "\n",
    "image, target = sample[0], sample[1]\n",
    "bbox=target\n",
    "# Inspect the sample\n",
    "print(\"Image shape:\", image.shape)\n",
    "print(\"Bounding boxes:\", bbox)\n",
    "# Test data loading using DataLoader\n",
    "batch_size = 4\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "fixed_size= (128,128)\n",
    "plotBoundaryBox(image,target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "#\n",
    "# Copyright (C) 2019-2021 Maxim Integrated Products, Inc. All Rights Reserved.\n",
    "#\n",
    "# Maxim Integrated Products, Inc. Default Copyright Notice:\n",
    "# https://www.maximintegrated.com/en/aboutus/legal/copyrights.html\n",
    "#\n",
    "###################################################################################################\n",
    "\"\"\"\n",
    "Classes and functions used to utilize the dataset.\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import ai8x\n",
    "from torchvision.datasets import WIDERFace\n",
    "\n",
    "\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, bboxes = sample[0], sample[1]['bboxes']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transforms.resize(image, (new_h, new_w))\n",
    "\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "        bboxes = bboxes * [new_w / w, new_h / h]\n",
    "\n",
    "        return img, bboxes\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, bboxes = sample[0], sample[1]\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        bboxes = bboxes - [left, top]\n",
    "\n",
    "        return image, bboxes\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, bboxes = sample[0], sample[1]['bboxes']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return torch.from_numpy(image), torch.from_numpy(bboxes)\n",
    "\n",
    "def widerfaces_get_datasets(data, load_train=True, load_test=True):\n",
    "    \"\"\"\n",
    "    Load the WIDER Faces dataset\n",
    "\n",
    "    The images are of multiple sizes, so they are rescaled to a predefined size.\n",
    "    \"\"\"\n",
    "    (data_dir, args) = data\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        #ai8x.normalize(args=args)\n",
    "    ])\n",
    "\n",
    "    if load_train:\n",
    "        print(\"Loading training dataset\")\n",
    "        train_transform = transforms.Compose([\n",
    "            #Rescale(256),\n",
    "            #RandomCrop(224),\n",
    "            transforms.ToTensor()\n",
    "            #ai8x.normalize()\n",
    "        ])\n",
    "\n",
    "        print('Function arguments to WIDERFace are: {}'.format(data_dir))\n",
    "\n",
    "        train_dataset = torchvision.datasets.WIDERFace(root=data_dir,split='train', transform=train_transform)\n",
    "        print('Train dataset is: {}'.format(train_dataset))\n",
    "        # print data types of each component in train_dataset\n",
    "        print('Train dataset data types are: {}'.format(train_dataset[0]))\n",
    "    else:\n",
    "        train_dataset = None\n",
    "\n",
    "    if load_test:\n",
    "        test_transform = transforms.Compose([\n",
    "            #Rescale(256),\n",
    "            #RandomCrop(224),\n",
    "            transforms.ToTensor()\n",
    "            \n",
    "            #ai8x.normalize()\n",
    "        ])\n",
    "        # Load validation dataset instead of test dataset, since test dataset is unlabeled\n",
    "        test_dataset = torchvision.datasets.WIDERFace(root=data_dir,split='test', transform=test_transform)\n",
    "    else:\n",
    "        test_dataset = None\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "datasets = [\n",
    "    {\n",
    "        'name': 'widerfaces',\n",
    "        'input': (3, 128, 128),\n",
    "        'output': [('x', float), ('y', float), ('w', float), ('h', float)],\n",
    "        'regression': True,\n",
    "        'loader': widerfaces_get_datasets,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s11ciz67kuNh"
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# WIDER Faces Network\n",
    "# Lionnus Kesting\n",
    "# Machine Learning on Microcontrollers\n",
    "# 2023 - ETH Zurich\n",
    "###################################################################################################\n",
    "\"\"\"\n",
    "WIDERFaceNet network description\n",
    "\"\"\"\n",
    "from signal import pause\n",
    "from torch import nn\n",
    "\n",
    "import ai8x\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Function to calculate linear layer dimensions\n",
    "def conv_shape(x, k=1, p=0, s=1, d=1):\n",
    "    return int((x + 2*p - d*(k - 1) - 1)/s + 1)\n",
    "\n",
    "class WIDERFaceNet(nn.Module):\n",
    "    def __init__(self, num_channels=3, dimensions = (64,64), bias=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(num_channels, 4, kernel_size=3, padding=1, bias=bias)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        dim_x = conv_shape(dimensions[0], k=3, p=1, s=1, d=1)\n",
    "        print(dim_x) \n",
    "\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=3, padding=1, bias=bias)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        dim_x = conv_shape(dimensions[0], k=3, p=1, s=1, d=1)\n",
    "        print(dim_x) \n",
    "\n",
    "\n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size=3, padding=1, bias=bias)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        dim_x = conv_shape(dimensions[0], k=3, p=1, s=1, d=1)\n",
    "        dim_y=dim_x #change when not square!\n",
    "        print(dim_x) \n",
    "\n",
    "        self.fc1 = nn.Linear(16 * 8*8, 32)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(32, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def widerfacenet(pretrained=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a WIDERFaceNet model.\n",
    "    \"\"\"\n",
    "    assert not pretrained\n",
    "    return WIDERFaceNet(**kwargs)\n",
    "\n",
    "\"\"\"\n",
    "Network description\n",
    "\"\"\"\n",
    "models = [\n",
    "    {\n",
    "        'name': 'widerfacenet',\n",
    "        'min_input': 1,\n",
    "        'dim': 3,\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hx5QEAlzqOgF"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters and settings\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = \"cpu\"#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the WIDER Faces dataset\n",
    "args=0\n",
    "data = ('/home/lionnus/OneDrive/Ubuntu/MLonMCU/maxim7800-face-detection',0)\n",
    "train_dataset,test_dataset= widerfaces_get_datasets(data,load_train=True, load_test=True)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an instance of your model\n",
    "model = WIDERFaceNet().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, bboxes in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = bboxes.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predicted_coords = model(images)\n",
    "        loss = criterion(predicted_coords, bboxes)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss}\")\n",
    "\n",
    "# Evaluation loop\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        predicted_coords = model(images)\n",
    "        loss = criterion(predicted_coords, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "avg_loss = total_loss / len(test_loader)\n",
    "print(f\"Average Test Loss: {avg_loss}\")\n",
    "\n",
    "# Save the trained model \n",
    "# torch.save(model.state_dict(), \"widerfacenet.pth\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Specify the subdirectory name for models\n",
    "models_dir = os.path.join(current_dir, \"models\")\n",
    "\n",
    "# Create the models directory if it doesn't exist\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "# Define the base model name\n",
    "base_model_name = \"widerfacenet_v\"\n",
    "\n",
    "# Find the latest version number in the models directory\n",
    "latest_version = 0\n",
    "for file_name in os.listdir(models_dir):\n",
    "    if file_name.startswith(base_model_name):\n",
    "        version_str = file_name[len(base_model_name):].split(\".\")[0]\n",
    "        version = int(version_str)\n",
    "        if version > latest_version:\n",
    "            latest_version = version\n",
    "\n",
    "# Increment the latest version number by 1\n",
    "new_version = latest_version + 1\n",
    "\n",
    "# Create the new model file path\n",
    "new_model_path = os.path.join(models_dir, f\"{base_model_name}{new_version}.pth\")\n",
    "\n",
    "# Save the model with the new name\n",
    "torch.save(model.state_dict(), new_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the saved pytorch model.pth on cpu\n",
    "model = WIDERFaceNet()\n",
    "device=\"cpu\"\n",
    "model.load_state_dict(torch.load(\"models/widerfacenet_v0.pth\",map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "# Run the trained PyTorch model on a sample from the test set\n",
    "# Get a random sample from the test_loader\n",
    "# images, labels = test_dataset[7]\n",
    "#import Image library\n",
    "from PIL import Image, ImageOps\n",
    "#load image test_pic\n",
    "image_test = Image.open('/home/lionnus/OneDrive/Ubuntu/MLonMCU/maxim7800-face-detection/test_pic2.jpg')\n",
    "image_test = ImageOps.exif_transpose(image_test)\n",
    "\n",
    "# Preprocess the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),  # Resize to match the model's input size\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "])\n",
    "image_test_trans = transform(image_test).unsqueeze(0)\n",
    "\n",
    "# Run model on image\n",
    "predicted_coords = model(image_test_trans.to(device))\n",
    "#convert to numpy\n",
    "predicted_coords = predicted_coords.cpu().detach().numpy()\n",
    "print('BBOX: ',predicted_coords[0])\n",
    "#plot the image_test with the predicted coordinates\n",
    "\n",
    "# Create a figure and plot the image\n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(image_test_trans.squeeze(0).permute(1, 2, 0))\n",
    "\n",
    "# Plot the predicted coordinates on the image\n",
    "x, y, w, h = predicted_coords[0]\n",
    "rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "# Set plot title and labels\n",
    "ax.set_title('Predicted Image with Coordinates')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MLonMCU_Lab4_HS2020 ",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04f39d85ef914506afba686773ff6552": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef3bec10c6984909860c6c750515629e",
      "placeholder": "​",
      "style": "IPY_MODEL_436eaf6820e94e4a9a46db170fe7b512",
      "value": " 9920512/? [00:01&lt;00:00, 6834916.09it/s]"
     }
    },
    "0fb7c10608464a4f8f98de6c08f23695": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71ec2ab9f883447f989f06d5bf617dac",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7b4fe3383d784957a8ee3ec177a3c37c",
      "value": 1
     }
    },
    "11695a6c6e734ac698c846a5e1454b6c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12776c8934b94d82a4b62ae2ac958f2a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17662a969b104381b9fd4fea18c247d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "33d3e7551e7f4f1db9bf2392eb97b5fd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36c627d5d6044a358ede80e5c20a0810": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "436eaf6820e94e4a9a46db170fe7b512": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "46acf6f3ec904e1c8a4b6287bff90b8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92a89d59b07348c78efe9362fe2a7f76",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_62e819c18b004dabb144e7c38e57de20",
      "value": 0
     }
    },
    "478a79313cd84555922590670687f0ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "568efdcf3dae4aa5933703b33beea3c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "62231147530f4e78a76fb186fb8df845": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_46acf6f3ec904e1c8a4b6287bff90b8a",
       "IPY_MODEL_e7be428874414f28865ba21aa26f28c5"
      ],
      "layout": "IPY_MODEL_33d3e7551e7f4f1db9bf2392eb97b5fd"
     }
    },
    "62e819c18b004dabb144e7c38e57de20": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6d2e484617384f379374cad7b392e1bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c43df9bd02504c3c83b9a46cc6db4437",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_36c627d5d6044a358ede80e5c20a0810",
      "value": 1
     }
    },
    "71ec2ab9f883447f989f06d5bf617dac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b4fe3383d784957a8ee3ec177a3c37c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7b672097ea5e48e2be28c48e54af41b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_806edeee5bf14fc7ba6b9e884bbff424",
      "placeholder": "​",
      "style": "IPY_MODEL_17662a969b104381b9fd4fea18c247d8",
      "value": " 1654784/? [00:18&lt;00:00, 531101.73it/s]"
     }
    },
    "806edeee5bf14fc7ba6b9e884bbff424": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92a89d59b07348c78efe9362fe2a7f76": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9caa426494d5415f83962ae9e3cbf0aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e12e2ea3992440a9945a21dac2e92451",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_568efdcf3dae4aa5933703b33beea3c6",
      "value": 0
     }
    },
    "b819c9f4b5894921ae0b860f04492475": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6d2e484617384f379374cad7b392e1bc",
       "IPY_MODEL_7b672097ea5e48e2be28c48e54af41b7"
      ],
      "layout": "IPY_MODEL_f5d911af83cf4b3c8e3e2a3c70cbc963"
     }
    },
    "c43df9bd02504c3c83b9a46cc6db4437": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0ae9af39dfd42259b947879cdeacb94": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9caa426494d5415f83962ae9e3cbf0aa",
       "IPY_MODEL_daef258daa4d421c9c3de074fccfa3ee"
      ],
      "layout": "IPY_MODEL_d18562f5524f40a0b4afd536a5947bd5"
     }
    },
    "d0d7de6c1fc4428c8cb725a88ae6b188": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d18562f5524f40a0b4afd536a5947bd5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daef258daa4d421c9c3de074fccfa3ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11695a6c6e734ac698c846a5e1454b6c",
      "placeholder": "​",
      "style": "IPY_MODEL_478a79313cd84555922590670687f0ee",
      "value": " 0/28881 [00:00&lt;?, ?it/s]"
     }
    },
    "ddf1a1155afa41a2bf59f675cd06995e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e12e2ea3992440a9945a21dac2e92451": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e30e67686ecc4f7bbb1eb9e59d883edc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0fb7c10608464a4f8f98de6c08f23695",
       "IPY_MODEL_04f39d85ef914506afba686773ff6552"
      ],
      "layout": "IPY_MODEL_12776c8934b94d82a4b62ae2ac958f2a"
     }
    },
    "e7be428874414f28865ba21aa26f28c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0d7de6c1fc4428c8cb725a88ae6b188",
      "placeholder": "​",
      "style": "IPY_MODEL_ddf1a1155afa41a2bf59f675cd06995e",
      "value": " 0/4542 [00:00&lt;?, ?it/s]"
     }
    },
    "ef3bec10c6984909860c6c750515629e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5d911af83cf4b3c8e3e2a3c70cbc963": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
